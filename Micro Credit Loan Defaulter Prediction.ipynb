{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Micro_Credit Loan Prediction</center>\n",
    "\n",
    "<img  src='https://miro.medium.com/max/527/1*glrB0KgjOcTiKUEx7T8tcA.png'></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "\n",
    "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:Blue; border:0' role=\"tab\" aria-controls=\"home\"><center>Quick navigation</center></h3>\n",
    "\n",
    "* [1. Introduction](#1)\n",
    "* [2. Data Reading and Analysis](#2)\n",
    "* [3. Data Exploration](#3)\n",
    "* [4. Data Visualization](#4)  \n",
    "* [5. Model Training](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "\n",
    "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0' role=\"tab\" aria-controls=\"home\"><center>Introduction</center><a id=1></a></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Microfinance Institution (MFI) is an organization that offers financial services to low income populations. MFS becomes very useful when targeting especially the unbanked poor families living in remote areas with not much sources of income. The Microfinance services (MFS) provided by MFI are Group Loans, Agricultural Loans, Individual Business Loans and so on.<br> \n",
    "Many microfinance institutions (MFI), experts and donorsare supporting the idea of using mobile financial services (MFS) which they feel are more convenient and efficient, and cost saving, than the traditional high-touch model used since long for the purpose of delivering microfinance services. Though, the MFI industry is primarily focusing on low income families and are very useful in such areas, the implementation of MFShas been uneven with both significant challenges and successes.\n",
    "Today, microfinance is widely accepted as a poverty-reduction tool, representing $70 billion in outstanding loans and a global outreach of 200 million clients.<br>\n",
    "We are working with one such client that is in Telecom Industry. They are a fixed wireless telecommunications network provider. They have launched various products and have developed its business and organization based on the budget operator model, offering better products at Lower Prices to all value conscious customers through a strategy of disruptive innovation that focuses on the subscriber. <br>\n",
    "They understand the importance of communication and how it affects a personâ€™s life, thus, focusing on providing their services and products to low income families and poor customers that can help them in the need of hour. <br>\n",
    "They arecollaborating with an MFI to provide micro-credit on mobile balances to be paid back in 5 days. The Consumer is believed to be defaulter if he deviates from the path of paying back the loaned amount within the time duration of 5 days. For the loan amount of 5 (in Indonesian Rupiah), payback amount should be6(in Indonesian Rupiah), while, for the loan amount of 10(in Indonesian Rupiah), the payback amount should be 12(in Indonesian Rupiah). <br>\n",
    "The sample data is provided to us from our client database. It is hereby given to you for this exercise. In order to improve the selection of customers for the credit, the client wants some predictions that could help them in further investment and improvement in selection of customers. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. label :Flag indicating whether the user paid back the credit amount within 5 days of issuing the loan{1:success, 0:failure}\n",
    "2. msisdn :mobile number of user\n",
    "3. aon :age on cellular network in days\n",
    "4. daily_decr30 :Daily amount spent from main account, averaged over last 30 days (in Indonesian Rupiah)\n",
    "5. daily_decr90 :Daily amount spent from main account, averaged over last 90 days (in Indonesian Rupiah)\n",
    "6. rental30 :Average main account balance over last 30 days\n",
    "7. rental90 :Average main account balance over last 90 days\n",
    "8. last_rech_date_ma :Number of days till last recharge of main account\n",
    "9. last_rech_date_da : Number of days till last recharge of data account\n",
    "10. last_rech_amt_ma : Amount of last recharge of main account (in Indonesian Rupiah)\n",
    "11. cnt_ma_rech30 : Number of times main account got recharged in last 30 days\n",
    "12. fr_ma_rech30 : Frequency of main account recharged in last 30 days\n",
    "13. sumamnt_ma_rech30 : Total amount of recharge in main account over last 30 days (in Indonesian Rupiah)\n",
    "14. medianamnt_ma_rech30 : Median of amount of recharges done in main account over last 30 days at user level (in Indonesian Rupiah)\n",
    "15. medianmarechprebal30 : Median of main account balance just before recharge in last 30 days at user level (in Indonesian Rupiah)\n",
    "16. cnt_ma_rech90 : Number of times main account got recharged in last 90 days\n",
    "17. fr_ma_rech90 : Frequency of main account recharged in last 90 days\n",
    "18. sumamnt_ma_rech90: Total amount of recharge in main account over last 90 days (in Indian Rupee)\n",
    "19. medianamnt_ma_rech90 :Median of amount of recharges done in main account over last 90 days at user level (in Indian Rupee)\n",
    "20. medianmarechprebal90 : Median of main account balance just before recharge in last 90 days at user level (in Indian Rupee)\n",
    "21. cnt_da_rech30 : Number of times data account got recharged in last 30 days\n",
    "22. fr_da_rech30 : Frequency of data account recharged in last 30 days\n",
    "23. cnt_da_rech90 : Number of times data account got recharged in last 90 days\n",
    "24. fr_da_rech90 : Frequency of data account recharged in last 90 days\n",
    "25. cnt_loans30 : Number of loans taken by user in last 30 days\n",
    "26. amnt_loans30 : Total amount of loans taken by user in last 30 days\n",
    "27. maxamnt_loans30 : maximum amount of loan taken by the user in last 30 days\n",
    "28. medianamnt_loans30 : Median of amounts of loan taken by the user in last 30 days\n",
    "29. cnt_loans90: Number of loans taken by user in last 90 days\n",
    "30. amnt_loans90 :Total amount of loans taken by user in last 90 days\n",
    "31. maxamnt_loans90 : maximum amount of loan taken by the user in last 90 days\n",
    "32. medianamnt_loans90: Median of amounts of loan taken by the user in last 90 days\n",
    "33. payback30 :Average payback time in days over last 30 days\n",
    "34. payback90: Average payback time in days over last 90 days\n",
    "35. pcircle: telecom circle\n",
    "36. pdate :date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id=\"top\"></a>\n",
    "\n",
    "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0' role=\"tab\" aria-controls=\"home\"><center>Data Reading and Analysis</center></h3><a id=2></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading data \n",
    "df=pd.read_csv('Data file.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's dive into depth \n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> From here we can observe that there is three object type attributes are there .They are msisdn,pcircle,pdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check null values \n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  It's looking perfect there is no null or missing values in this data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"shape of data set is \",df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "\n",
    "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0' role=\"tab\" aria-controls=\"home\"><center>Data Preprocessing</center><a id=3></a></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Remove columns where number of unique value is only 1.\n",
    "Let's look at no of unique values for each column.We will remove all columns where number of unique value is only 1 because that will not make any sense in the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = df.nunique()\n",
    "unique = unique[unique.values == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(labels = list(unique.index), axis =1, inplace=True)\n",
    "print(\"So now we are left with\",df.shape ,\"rows & columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Here we check the summary of object and datetime columns\n",
    "df.describe(include=['object','datetime']).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observation:</b>\n",
    "\n",
    "* Summary statistics shows all the statistics of our dataset i.e. mean, median and other calculation.\n",
    "* Mean is greater than median in all the columns so aur data is right skewed.\n",
    "* The difference between 75% and maximum is higher that's why outliers are removed which needs to be removed.\n",
    "* The pdate column tells the date when the data is collect. It contains only three month data.\n",
    "* msidn is a mobile number of user and mobile number is unique for every customers. There are only 186243 unique number out of 209593 so rest of the data is duplicates entry so we have to remove those entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deleting the duplicates entry in msidn column\n",
    "df = df.drop_duplicates(subset = 'msisdn',keep='first')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "\n",
    "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0' role=\"tab\" aria-controls=\"home\"><center>Data Exploration</center><a id=3></a></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Printing the object datatypes and their unique values.\n",
    "\n",
    "for column in df.columns:\n",
    "    if df[column].dtypes == object:\n",
    "        print(str(column) + ' : ' + str(df[column].unique()))\n",
    "        print('**********************************************************************************************************')\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<b>Observation:\n",
    "</b>\n",
    "* contains only one circle area data. So it have not any impact in our model if we drop this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Printing the float datatype columns and number of unique values in the particular columns.\n",
    "\n",
    "for column in df.columns:\n",
    "    if df[column].dtype==np.number:\n",
    "        print(str(column) + ' : ' + str(df[column].nunique()))\n",
    "        print(df[column].nunique())\n",
    "        print('//////*******************************************************************************///////')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the number of number of defaulter and non defaulter customers.\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Checking the defaulter customers percentage wise.\n",
    "df['label'].value_counts(normalize=True) *100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<b>Observation:\n",
    "</b>\n",
    "* After seeing the label column which is also our target feature for this dataset it is clearly shown that 86.11% of\n",
    "* data is label 1 and only 13.8% of data is label 0 so our dataset is implanced. So before making the ML model first we have to do sampling to get rid off imblance dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check cor-relation\n",
    "df_cor = df.corr()\n",
    "df_cor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observation:\n",
    "</b>\n",
    "* daily_decr30 and daily_decr90 features are highly correlated with each otheer.\n",
    "* rental30 and rental90 features are highly correlated with each other.\n",
    "* cnt_loans30 and amount_loans30 columns are highly correlated with each other.\n",
    "* amount_loans30 is also highly correlated with amount_loans90 column.\n",
    "* medianamnt_loans30 and medianamnt_loans90 is highly correlated with each other.\n",
    "* We have to drop one of the features which are highly correlated with other feayures. And if we dont do this then our model will face multicolinearity problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dropping the columns which is highly correlated with each other do avoid multicolinearity problem.\n",
    "df.drop(columns=['daily_decr30','rental30','amnt_loans30','medianamnt_loans30'],axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now checking the shape\n",
    "print(df.shape)\n",
    "#Checking the unique value in pdate column.\n",
    "df['pdate'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making the new column Day, Month and year from pdate column\n",
    "df['pDay']=pd.to_datetime(df['pdate'],format='%Y/%m/%d').dt.day\n",
    "df['pMonth']=pd.to_datetime(df['pdate'],format='%Y/%m/%d').dt.month\n",
    "df['pYear']=pd.to_datetime(df['pdate'],format='%Y/%m/%d').dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the number of months \n",
    "df['pMonth'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After fetching the data from pdate column now we are going to drop it because it has not any significant role.\n",
    "df.drop(columns=['pdate'],axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seprate the categorical columns and Numerical columns\n",
    "cat_df,num_df=[],[]\n",
    "\n",
    "for i in df.columns:\n",
    "    if df[i].dtype==object:\n",
    "        cat_df.append(i)\n",
    "    elif (df[i].dtypes=='int64') | (df[i].dtypes=='float64') | (df[i].dtypes=='int32'):\n",
    "        num_df.append(i)\n",
    "    else: continue\n",
    "        \n",
    "print('>>> Total Number of Feature::', df.shape[1])\n",
    "print('>>> Number of categorical features::', len(cat_df))\n",
    "print('>>> Number of Numerical Feature::', len(num_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "\n",
    "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0' role=\"tab\" aria-controls=\"home\"><center>Data Visualization</center><a id=4></a></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Checking the correlation with target variable\n",
    "plt.figure(figsize=(16,8))\n",
    "df.drop('label', axis=1).corrwith(df['label']).plot(kind='bar',grid=True)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.title(\"Correlation with target Variable that is label column\",fontsize=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observation:</b>\n",
    "* Here we see the correlation of the columns with respect to the target column that is label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the number of Fraud cases.\n",
    "sns.countplot(x='label', data=df, palette='magma')\n",
    "plt.title('No of defaulter/Non-defaulter Case',fontsize=18)\n",
    "plt.show()\n",
    "\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observation:\n",
    "</b>\n",
    "* Label 1 indicates loan has been payed i.e Non-Defaulter and label 0 indicates indicates that the loan has not beenpayed i.e. defaulter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the Histogram\n",
    "df.hist(figsize=(20,20),color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observation:</b>\n",
    "* We plot the histogram to display the shape and spread of continuous sample data.In a histogram, each bar groups numbers into ranges. Taller bars show that more data falls in that range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Customer label according to Date\n",
    "plt.figure(figsize=(20,8))\n",
    "sns.countplot(x=\"pDay\", hue='label', data=df, palette='autumn_r')\n",
    "plt.title(\"Customers label according to Date\", fontsize=25)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Counting of Customers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Customer label according to Month\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(x=\"pMonth\", hue='label', data=df, palette='cool')\n",
    "plt.title(\"Customers label according to month\", fontsize=25)\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Counting of Customers')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observation:\n",
    "</b>\n",
    "* The first figure which is date vs label shows that the customers who did not pay their loans are from date 10 to 23.\n",
    "* There are severals customers at June and July month who did not pay their loan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking skewness\n",
    "\n",
    "for col in df.describe().columns:\n",
    "    sns.distplot(df[col],color='r')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Treating Skewness via square root method.\n",
    "#df.skew()\n",
    "#for col in df.skew().index:\n",
    "    #if col in df.describe().columns:\n",
    "        #if df[col].skew()>0.55:\n",
    "            #df[col]=np.sqrt(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting outliers\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2, figsize = (18, 10))\n",
    "sns.boxplot(ax=ax1, x = 'label', y = 'last_rech_date_ma', hue = 'label', data = df)\n",
    "sns.boxplot(ax=ax2, x = 'label', y = 'last_rech_date_da', hue = 'label', data = df)\n",
    "sns.boxplot(ax=ax3, x = 'label', y = 'cnt_da_rech30', hue = 'label', data = df)\n",
    "sns.boxplot(ax=ax4, x = 'label', y = 'fr_da_rech30', hue = 'label', data = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Observation:\n",
    "</b>\n",
    "* There are too many outliers present in our dataset.So we need to remove it. But before removing please check that \n",
    "only 8 to 10% of data removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a copy of our dataset\n",
    "df2=df1.copy()\n",
    "#Dropping the object columns\n",
    "df1.drop(columns=['msisdn','pdate'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "z=np.abs(zscore(df1))\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=3\n",
    "print(np.where(z>3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1_new=df1[(z<3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Checking the shape\n",
    "print(df1.shape,'\\t\\t',df1_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting the categorical data into numeric variables\n",
    "# Transform Non numeric columns into Numeric columns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le=LabelEncoder()\n",
    "\n",
    "for column in df.columns:\n",
    "    if df[column].dtype==np.number:\n",
    "        continue\n",
    "    df[column]=le.fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature importance\n",
    "\n",
    "#Splitting the data into x and y\n",
    "x = df.drop(['label'], axis=1)\n",
    "\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(max_depth=3)\n",
    "dt.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_features = pd.DataFrame(dt.feature_importances_, index=x.columns, columns=['feat_importance'])\n",
    "dt_features.sort_values('feat_importance').tail(10).plot.barh()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "By looking at the daily_decr90 which is Daily amount spent from main account, averaged over last 90 days (in Indonesian Rupiah), it seems that this feature helps to discriminate the data indeed. This feature can bring insights for company when analyzing a customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"top\"></a>\n",
    "\n",
    "<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n",
    "<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='background:orange; border:0' role=\"tab\" aria-controls=\"home\"><center>Model Training</center><a id=5></a></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling in input variables\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss=StandardScaler()\n",
    "x=ss.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Splitting the data into training and testing data\n",
    "\n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=.20,random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN=KNeighborsClassifier(n_neighbors=10)\n",
    "LR=LogisticRegression()\n",
    "DT=DecisionTreeClassifier(random_state=20)\n",
    "GNB=GaussianNB()\n",
    "RF=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('KNeighborsClassifier', KNN))\n",
    "models.append(('LogisticRegression', LR))\n",
    "models.append(('DecisionTreeClassifier',DT))\n",
    "models.append(('GaussianNB', GNB))\n",
    "models.append(('RandomForestClassifier', RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,roc_curve,auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model=[]\n",
    "score=[]\n",
    "cvs=[]\n",
    "rocscore=[]\n",
    "for name,model in models:\n",
    "    print('****************************',name,'********************************')\n",
    "    print('\\n')\n",
    "    Model.append(name)\n",
    "    model.fit(x_train,y_train.values.ravel())\n",
    "    print(model)\n",
    "    pre=model.predict(x_test)\n",
    "    print('\\n')\n",
    "    AS=accuracy_score(y_test,pre)\n",
    "    print('Accuracy score = ', AS)\n",
    "    score.append(AS*100)\n",
    "    print('\\n')\n",
    "    sc=cross_val_score(model,x,y,cv=10,scoring='accuracy').mean()\n",
    "    print('Cross_val_Score = ', sc)\n",
    "    cvs.append(sc*100)\n",
    "    print('\\n')\n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test,pre)\n",
    "    roc_auc= auc(false_positive_rate, true_positive_rate)\n",
    "    print('roc_auc_score = ',roc_auc)\n",
    "    rocscore.append(roc_auc*100)\n",
    "    print('\\n')\n",
    "    print('classification_report\\n',classification_report(y_test,pre))\n",
    "    print('\\n')\n",
    "    cm=confusion_matrix(y_test,pre)\n",
    "    print(cm)\n",
    "    print('\\n')\n",
    "    plt.figure(figsize=(10,40))\n",
    "    plt.subplot(911)\n",
    "    plt.title(name)\n",
    "    print(sns.heatmap(cm,annot=True))\n",
    "    plt.subplot(912)\n",
    "    plt.title(name)\n",
    "    plt.plot(false_positive_rate, true_positive_rate, label = 'AUC= %0.2f'%roc_auc)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result=pd.DataFrame({'Model': Model, 'Accuracy_score': score, 'Cross_val_score':cvs, 'Roc_auc_curve':rocscore})\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
